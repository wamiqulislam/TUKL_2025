{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12597441,"sourceType":"datasetVersion","datasetId":7956709}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport copy\n\nimport math\nimport torch\nfrom torch.nn.modules.transformer import TransformerEncoder, TransformerEncoderLayer\nfrom torch.nn.modules import LayerNorm, Linear, ReLU\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport sklearn.metrics\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport pickle\nfrom torch.utils.data import DataLoader\n\nfrom torch.utils.data import Sampler\nimport numpy as np\nimport random\nfrom collections import defaultdict\nimport csv\nimport os\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nimport numpy as np\nimport torch\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn.neighbors import NearestNeighbors\nimport numpy as np\nimport math\nfrom torch.utils.data import Sampler, DataLoader, Dataset\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\n\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:49:18.213293Z","iopub.execute_input":"2025-07-31T09:49:18.213678Z","iopub.status.idle":"2025-07-31T09:49:18.222484Z","shell.execute_reply.started":"2025-07-31T09:49:18.213654Z","shell.execute_reply":"2025-07-31T09:49:18.221240Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Inputs","metadata":{}},{"cell_type":"code","source":"#shape (Num, Channels, Timesteps)\nInput_path = '/kaggle/input/active-learning-subset/tar_image_subset.npy' \n#shape (Num)\nLabels_path = '/kaggle/input/active-learning-subset/label_target_subset.npy'\n\nbackbone_model_path = '/kaggle/input/active-learning-subset/backboneSiteA2019.pth'\nfc_model_path = '/kaggle/input/active-learning-subset/fcSiteA2019.pth'\n\n\"\"\"\n----------------------------------------------------------------------------------------\nLoss Function selection\nCurrently available:\n\"ce = cross entropy loss\",\"ls = LabelSmoothingCrossEntropyLoss\"\n\"\"\"\nloss_mode = \"ls\"\n\n\"\"\"\n---------------------------------------------------------------------------------------------\nActive Learning Method(s) to use\nCurrently available:\n\"random\", \"entropy\", \"margin\", \"least_confident\", \"diversity\", \"entropy_diversity\", \"density\"\n\"\"\"\nstrategies = [ 'margin', 'least_confident']\n\n\"\"\"\n----------------------------------------------------------------------------------------\nShape(s) of data to test on:\n(Initial samples, Iterations of AL loop, Query Sample Size)\n\"\"\"\ndata = [(100,3,10), (300,3,10)]\n\nbatch_size = 20\nepochs = 15\nvariable_epochs = True\ntest_size = 0.2\nlr = 1e-1\nweight_decay = 1e-4\nlabel_smoothing = 0.1\nignore_index = -100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:49:18.224285Z","iopub.execute_input":"2025-07-31T09:49:18.224616Z","iopub.status.idle":"2025-07-31T09:49:18.249237Z","shell.execute_reply.started":"2025-07-31T09:49:18.224594Z","shell.execute_reply":"2025-07-31T09:49:18.248108Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"#prints how many labeled samples used, and how many samples will hte model effectively be trained on\ndef eff_total_labeled_samples(init, iterations, query):\n    return round(iterations * init + query * (iterations * (iterations - 1)) // 2)\n\ndef total_labeled_samples(init, iterations, query):\n    return init+query*iterations\n\nprint(\"Samples used: \",[total_labeled_samples(a, b, c) for a, b, c in data])\nprint(\"Effective Samples trained on: \",[eff_total_labeled_samples(a, b, c) for a, b, c in data])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:49:18.250941Z","iopub.execute_input":"2025-07-31T09:49:18.251227Z","iopub.status.idle":"2025-07-31T09:49:18.271434Z","shell.execute_reply.started":"2025-07-31T09:49:18.251205Z","shell.execute_reply":"2025-07-31T09:49:18.270099Z"}},"outputs":[{"name":"stdout","text":"Samples used:  [130, 330]\nEffective Samples trained on:  [330, 930]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# Data Loader","metadata":{}},{"cell_type":"code","source":"def print_distribution(labels, name=\"\"):\n    counts = Counter(labels)\n    total = sum(counts.values())\n    print(f\"Distribution in {name}:\")\n    for label in sorted(counts):\n        pct = 100 * counts[label] / total\n        print(f\"  Class {label}: {counts[label]} ({pct:.1f}%)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:49:18.272606Z","iopub.execute_input":"2025-07-31T09:49:18.272854Z","iopub.status.idle":"2025-07-31T09:49:18.290835Z","shell.execute_reply.started":"2025-07-31T09:49:18.272835Z","shell.execute_reply":"2025-07-31T09:49:18.289766Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"X = np.load(Input_path) \ny = np.load(Labels_path)\n\nX_pool, X_val, y_pool, y_val = train_test_split(X, y, test_size=test_size, stratify=y, random_state=42)\n\ny_sample = y\nX_sample = X\n\n\n# Checking normalisation\nchannel_variance = np.var(X_sample, axis=2).mean(axis=0)\nchannel_mean = X_sample.mean(axis=(0, 2))\nchannel_std = X_sample.std(axis=(0, 2))\ndf_stats = pd.DataFrame({\n    'channel': range(6),\n    'mean': channel_mean,\n    'std_dev': channel_std,\n    'variance': channel_variance\n})\nprint(\"\\nMean, Std Dev and Variance per Channel:\")\nprint(df_stats)\n\nprint(f\"X shape: {X.shape}\")\nprint(f\"y shape: {y.shape}\")\nprint_distribution(y, name=\"X\")\nprint(f\"X_val shape: {X_val.shape}\")\nprint(f\"y_val  shape: {y_val.shape}\")\nprint_distribution(y_val, name=\"X_val\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:49:18.293572Z","iopub.execute_input":"2025-07-31T09:49:18.293892Z","iopub.status.idle":"2025-07-31T09:49:18.411606Z","shell.execute_reply.started":"2025-07-31T09:49:18.293870Z","shell.execute_reply":"2025-07-31T09:49:18.410030Z"}},"outputs":[{"name":"stdout","text":"\nMean, Std Dev and Variance per Channel:\n   channel      mean   std_dev  variance\n0        0  0.004546  0.999189  0.730689\n1        1  0.004955  0.999538  0.721030\n2        2  0.003958  1.000457  0.755685\n3        3  0.001807  1.000751  0.783507\n4        4  0.001153  1.000271  0.634434\n5        5  0.001723  1.000909  0.731176\nX shape: (20000, 6, 28)\ny shape: (20000,)\nDistribution in X:\n  Class 0: 9081 (45.4%)\n  Class 1: 2603 (13.0%)\n  Class 2: 8316 (41.6%)\nX_val shape: (4000, 6, 28)\ny_val  shape: (4000,)\nDistribution in X_val:\n  Class 0: 1816 (45.4%)\n  Class 1: 521 (13.0%)\n  Class 2: 1663 (41.6%)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"class Dataset():\n    def __init__(self, X, y):\n        self.X = torch.tensor(X, dtype=torch.float32)\n        self.y = torch.tensor(y, dtype=torch.long)\n\n    def __getitem__(self, index):\n        return {\n            \"x\": self.X[index],  # shape: [C, T]\n            \"y\": self.y[index]\n        }\n\n    def __len__(self):\n        return len(self.X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:49:18.412609Z","iopub.execute_input":"2025-07-31T09:49:18.413050Z","iopub.status.idle":"2025-07-31T09:49:18.419875Z","shell.execute_reply.started":"2025-07-31T09:49:18.413017Z","shell.execute_reply":"2025-07-31T09:49:18.418646Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"label_counts = Counter(y_sample)\n\n# Total number of samples\ntotal_samples = sum(label_counts.values())\n\n# Number of classes\nnum_classes = max(label_counts.keys()) + 1  # assuming labels are integers from 0-n\n\n# Computing weights for each class as inverse frequency\nclass_weights = []\nfor i in range(num_classes):\n    count = label_counts.get(i, 0)\n    if count == 0:\n        class_weights.append(1e-6)  # ignoring non-present classes\n    else:\n        class_weights.append(total_samples / (num_classes * count))\n\nprint(f\"class weights: {class_weights}\")\n# Convert to torch tensor for CE loss function\nclass_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:49:18.420957Z","iopub.execute_input":"2025-07-31T09:49:18.421252Z","iopub.status.idle":"2025-07-31T09:49:18.445249Z","shell.execute_reply.started":"2025-07-31T09:49:18.421229Z","shell.execute_reply":"2025-07-31T09:49:18.444076Z"}},"outputs":[{"name":"stdout","text":"class weights: [0.7341335388907242, 2.5611473940325267, 0.801667468334135]\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# Loss Functions","metadata":{}},{"cell_type":"code","source":"class Loss:\n    def __init__(self, weight=None, ignore_index=-100, device=None, smoothing=0.1):\n        self.weight = weight\n        self.ignore_index = ignore_index\n        self.device = device\n        self.smoothing = smoothing\n        self.criterion = None\n        self.loss_func = None\n\n    def build(self, mode='ce'):\n        \"\"\"\n        Available modes: 'ce', 'ls'\n        \"\"\"\n        if mode == 'ce':\n            self.criterion = nn.CrossEntropyLoss(weight=self.weight, ignore_index=self.ignore_index)\n            self.loss_func = self.cross_entropy_loss\n\n        elif mode == 'ls':\n            self.loss_func = self.label_smoothing_loss\n\n        else:\n            raise NotImplementedError(f\"Loss mode '{mode}' is not implemented.\")\n\n        if self.device is not None and self.criterion is not None:\n            self.criterion = self.criterion.to(self.device)\n\n        return self.loss_func\n\n    def cross_entropy_loss(self, logits, targets):\n        return self.criterion(logits, targets)\n\n    def label_smoothing_loss(self, logits, targets):\n        log_probs = F.log_softmax(logits, dim=-1)\n        \n        valid = targets != self.ignore_index\n        log_probs = log_probs[valid]\n        targets = targets[valid]\n        \n        nll_loss = -log_probs.gather(dim=-1, index=targets.unsqueeze(1)).squeeze(1)\n        smooth_loss = -log_probs.mean(dim=-1)\n        loss = (1.0 - self.smoothing) * nll_loss + self.smoothing * smooth_loss\n    \n        if self.weight is not None:\n            weight = self.weight.to(logits.device)\n            loss = loss * weight[targets]\n    \n        return loss.mean()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:49:18.446432Z","iopub.execute_input":"2025-07-31T09:49:18.446711Z","iopub.status.idle":"2025-07-31T09:49:18.467272Z","shell.execute_reply.started":"2025-07-31T09:49:18.446689Z","shell.execute_reply":"2025-07-31T09:49:18.466054Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"################ CNN Backbone \ndef conv_block(in_channels: int, out_channels: int, dropout=0.3) -> nn.Module:\n    return nn.Sequential(\n        nn.Conv1d(in_channels, out_channels, 5, padding='same'),\n        nn.BatchNorm1d(out_channels),\n        nn.ReLU(),\n        nn.Dropout(dropout),\n    )\n\nclass cnn(nn.Module):\n    def __init__(self):\n        super(cnn, self).__init__()\n        self.conv1 = conv_block(6, 64)\n        self.conv2 = conv_block(64, 128)\n        self.conv3 = conv_block(128, 256)\n        self.conv4 = conv_block(256, 512)\n        self.conv5 = conv_block(512, 1024)\n        self.global_pool = nn.AdaptiveAvgPool1d(1)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.conv5(x)\n        x = self.global_pool(x)\n        x = x.view(x.size(0), -1)\n        return x\n\n \n################ Fully connected network\nclass FC(nn.Module):\n    def __init__(self, input_dim):\n        super(FC, self).__init__()\n        self.dropout = nn.Dropout(0.5)\n        self.fco = nn.Linear(input_dim, 3)\n\n    def forward(self, x):\n        x = self.dropout(x)\n        x = self.fco(x)\n        return x\n\n\n\nclass FullModel(nn.Module):\n    def __init__(self, backbone, fc):\n        super().__init__()\n        self.backbone = backbone\n        self.fc = fc\n\n    def forward(self, x):\n        feat = self.backbone(x)\n        out = self.fc(feat)\n        return feat, out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:49:18.468514Z","iopub.execute_input":"2025-07-31T09:49:18.468902Z","iopub.status.idle":"2025-07-31T09:49:18.493563Z","shell.execute_reply.started":"2025-07-31T09:49:18.468877Z","shell.execute_reply":"2025-07-31T09:49:18.492201Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"#pretrained weights\nmap_location=torch.device(device)\n\nbackbone = cnn()\nfc = FC(1024)\n\n#loading backbone weights\nstate_dict = torch.load(backbone_model_path, map_location=map_location)\n# Remove \"module.\" prefix\nnew_state_dict = {}\nfor k, v in state_dict.items():\n    new_key = k.replace(\"module.\", \"\")  # remove module. prefix\n    new_state_dict[new_key] = v\n\nbackbone.load_state_dict(new_state_dict)\n\n#loading fc weights\nstate_dict = torch.load(fc_model_path, map_location=map_location)\n# Remove \"module.\" prefix\nnew_state_dict = {}\nfor k, v in state_dict.items():\n    new_key = k.replace(\"module.\", \"\")  # remove module. prefix\n    new_state_dict[new_key] = v\n\nfc.load_state_dict(new_state_dict)\n\nmodel = FullModel(backbone, fc).to(device)\ninitial_state_dict = copy.deepcopy(model.state_dict())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:49:18.494636Z","iopub.execute_input":"2025-07-31T09:49:18.495137Z","iopub.status.idle":"2025-07-31T09:49:18.569518Z","shell.execute_reply.started":"2025-07-31T09:49:18.495101Z","shell.execute_reply":"2025-07-31T09:49:18.568474Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"# Active Learning methods","metadata":{}},{"cell_type":"code","source":"def query_samples(model, dataset, query_size, strategy, device, already_selected_idx=None):\n    model.eval()\n\n    #check if strategy is correct\n    strategy = strategy.strip().lower()\n    allowed_strategies = [\n        \"entropy\", \"least_confident\", \"margin\", \"random\",\n        \"diversity\", \"density\", \"entropy_diversity\"\n    ]\n    \n    if strategy not in allowed_strategies:\n        raise ValueError(f\"[ERROR] Unknown strategy '{strategy}'. Must be one of: {allowed_strategies}\")\n\n    \n    dataloader = DataLoader(dataset, batch_size=128)\n    all_scores = []\n    all_features = []\n    if already_selected_idx is None:\n        already_selected_idx = []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            x = batch[\"x\"].to(device)\n            features, out = model(x)\n            probs = F.softmax(out, dim=1)\n\n            if strategy in [\"entropy\", \"least_confident\", \"margin\", \"random\", \"entropy_diversity\"]:\n                score = None\n                if strategy in [\"entropy\", \"entropy_diversity\"]:\n                    score = -torch.sum(probs * torch.log(probs + 1e-10), dim=1)\n                elif strategy == \"least_confident\":\n                    score = 1 - probs.max(dim=1)[0]\n                elif strategy == \"margin\":\n                    sorted_probs, _ = probs.sort(dim=1, descending=True)\n                    score = -(sorted_probs[:, 0] - sorted_probs[:, 1])\n                elif strategy == \"random\":\n                    score = torch.rand(len(x), device=device)\n\n                all_scores.extend(score.cpu().numpy())\n\n            if strategy in [\"diversity\", \"density\", \"entropy_diversity\"]:\n                all_features.append(features.cpu().numpy())\n\n    if strategy in [\"entropy\", \"least_confident\", \"margin\", \"random\"]:\n        indices = np.argsort(all_scores)[-query_size:]\n        return indices\n\n    all_features = np.concatenate(all_features, axis=0)\n\n    if strategy == \"diversity\":\n        # Core-set (k-Center Greedy)\n        if already_selected_idx is None or len(already_selected_idx) == 0:\n            selected = [np.random.randint(len(all_features))]\n        else:\n            selected = already_selected_idx.copy()\n\n        selected_features = all_features[selected]\n        remaining = list(set(range(len(all_features))) - set(selected))\n\n        for _ in range(query_size):\n            dists = pairwise_distances(all_features[remaining], selected_features, metric=\"euclidean\")\n            min_dists = np.min(dists, axis=1)\n            next_idx = remaining[np.argmax(min_dists)]\n            selected.append(next_idx)\n            selected_features = np.vstack([selected_features, all_features[next_idx].reshape(1, -1)])\n            remaining.remove(next_idx)\n\n        new_indices = list(set(selected) - set(already_selected_idx))[-query_size:]\n        return np.array(new_indices)\n\n    elif strategy == \"density\":\n        if all_features.shape[1] > 64:\n            from sklearn.decomposition import PCA\n            pca = PCA(n_components=64)\n            all_features = pca.fit_transform(all_features)\n\n        all_features = all_features.astype(np.float32)\n        nbrs = NearestNeighbors(n_neighbors=6, algorithm='auto', metric='euclidean').fit(all_features)\n        distances, _ = nbrs.kneighbors(all_features)\n        avg_neighbor_dist = distances[:, 1:].mean(axis=1)\n        density_scores = -avg_neighbor_dist\n        indices = np.argsort(density_scores)[-query_size:]\n        return indices\n\n    elif strategy == \"entropy_diversity\":\n        # Hybrid: Select top-2×query_size most uncertain samples, then apply core-set\n        all_scores = np.array(all_scores)\n        all_features = np.array(all_features)\n\n        top_uncertain_idx = np.argsort(all_scores)[-2 * query_size:]\n        uncertain_features = all_features[top_uncertain_idx]\n\n        # Core-set on uncertain samples\n        selected = [np.random.randint(len(uncertain_features))]\n        selected_features = uncertain_features[selected]\n        remaining = list(set(range(len(uncertain_features))) - set(selected))\n\n        for _ in range(query_size - 1):\n            dists = pairwise_distances(uncertain_features[remaining], selected_features, metric=\"euclidean\")\n            min_dists = np.min(dists, axis=1)\n            next_idx = remaining[np.argmax(min_dists)]\n            selected.append(next_idx)\n            selected_features = np.vstack([selected_features, uncertain_features[next_idx].reshape(1, -1)])\n            remaining.remove(next_idx)\n\n        final_indices = top_uncertain_idx[selected]\n        return np.array(final_indices)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:49:18.572637Z","iopub.execute_input":"2025-07-31T09:49:18.572992Z","iopub.status.idle":"2025-07-31T09:49:18.592697Z","shell.execute_reply.started":"2025-07-31T09:49:18.572959Z","shell.execute_reply":"2025-07-31T09:49:18.591715Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"# Train/eval loop","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, dataloader, optimizer, loss_fn, device):\n    model.train()\n    total_loss, all_preds, all_targets = 0, [], []\n    \n    for batch in dataloader:\n        x, y = batch[\"x\"].to(device), batch[\"y\"].to(device)\n\n        optimizer.zero_grad()\n        _, out = model(x)\n        loss = loss_fn(out, y)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item() * len(x)\n        preds = torch.argmax(out, dim=1)\n        all_preds.extend(preds.cpu().numpy())\n        all_targets.extend(y.cpu().numpy())\n\n    avg_loss = total_loss / len(dataloader.dataset)\n    acc = np.mean(np.array(all_preds) == np.array(all_targets))\n    f1s = sklearn.metrics.f1_score(all_targets, all_preds, average=None)\n    return avg_loss, acc, f1s, np.mean(f1s)\n\n\n\ndef _eval_perf(model, dataloader, device, loss_fn=None):\n    model.eval()\n    pred, gt = [], []\n    total_loss = 0\n\n    with torch.no_grad():\n        for batch in dataloader:\n            x, y = batch[\"x\"].to(device), batch[\"y\"].to(device)\n            _, outputs = model(x)\n            preds = torch.argmax(outputs, dim=1)\n            if loss_fn:\n                total_loss += loss_fn(outputs, y).item() * len(x)\n\n            pred.extend(preds.cpu().numpy())\n            gt.extend(y.cpu().numpy())\n\n    acc = np.mean(np.array(pred) == np.array(gt))\n    f1s = sklearn.metrics.f1_score(gt, pred, average=None)\n    avg_f1 = np.mean(f1s)\n\n    if loss_fn:\n        avg_loss = total_loss / len(dataloader.dataset)\n        return avg_loss, f1s, acc, avg_f1\n    else:\n        return 0, f1s, acc, avg_f1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:49:18.593640Z","iopub.execute_input":"2025-07-31T09:49:18.593973Z","iopub.status.idle":"2025-07-31T09:49:18.612554Z","shell.execute_reply.started":"2025-07-31T09:49:18.593951Z","shell.execute_reply":"2025-07-31T09:49:18.611456Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def plot_round_metrics(history):\n    round_id = len(history[\"epoch_metrics\"]) - 1\n    epoch_stats = history[\"epoch_metrics\"][round_id]\n    epochs = list(range(1, len(epoch_stats) + 1))\n\n    train_loss = [e[\"train_loss\"] for e in epoch_stats]\n    val_loss = [e[\"val_loss\"] for e in epoch_stats]\n    train_acc = [e[\"train_acc\"] for e in epoch_stats]\n    train_f1 = [e[\"train_avg_f1\"] for e in epoch_stats]\n    val_acc = [e[\"val_acc\"] for e in epoch_stats]\n    val_f1 = [e[\"val_avg_f1\"] for e in epoch_stats]\n\n    plt.figure(figsize=(15, 4))\n\n    # Loss plot\n    plt.subplot(1, 3, 1)\n    plt.plot(epochs, train_loss, label=\"Train Loss\")\n    plt.plot(epochs, val_loss, label=\"Val Loss\")\n    plt.title(f\"[Round {round_id+1}] Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n\n    # Accuracy plot\n    plt.subplot(1, 3, 2)\n    plt.plot(epochs, train_acc, label=\"Train Acc\")\n    plt.plot(epochs, val_acc, label=\"Val Acc\")\n    plt.title(f\"[Round {round_id+1}] Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n\n    # Avg F1 plot\n    plt.subplot(1, 3, 3)\n    plt.plot(epochs, train_f1, label=\"Train F1\")\n    plt.plot(epochs, val_f1, label=\"Val F1\")\n    plt.title(f\"[Round {round_id+1}] Avg F1\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Avg F1\")\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n\n\ndef plot_final_performance(history):\n    samples = history[\"samples\"]\n    val_acc = history[\"round_val_acc\"]\n    val_f1 = history[\"round_val_avg_f1\"]\n\n    plt.figure(figsize=(10, 4))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(samples, val_acc, marker='o')\n    plt.title(\"Val Accuracy vs Labeled Samples\")\n    plt.xlabel(\"Labeled Samples\")\n    plt.ylabel(\"Accuracy\")\n\n    plt.subplot(1, 2, 2)\n    plt.plot(samples, val_f1, marker='o')\n    plt.title(\"Val Avg F1 vs Labeled Samples\")\n    plt.xlabel(\"Labeled Samples\")\n    plt.ylabel(\"Avg F1\")\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:49:18.613715Z","iopub.execute_input":"2025-07-31T09:49:18.614062Z","iopub.status.idle":"2025-07-31T09:49:18.637944Z","shell.execute_reply.started":"2025-07-31T09:49:18.614041Z","shell.execute_reply":"2025-07-31T09:49:18.636880Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"# Active Learning Loop","metadata":{}},{"cell_type":"code","source":"def active_learning_loop(model, labeled_dataset, unlabeled_dataset, val_dataset, strategy, device, iters=10, query_size=100, final_epochs=10, loss_mode = 'ce', batch_size = 16):\n    \n    loss_handler = Loss(weight=class_weights, ignore_index=ignore_index, device=device, smoothing= label_smoothing)\n    loss_fn = loss_handler.build(mode=loss_mode) \n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n    \n    history = {\n        \"strategy\": strategy,\n        \"samples\": [],\n        \"epoch_metrics\": [],\n        \"round_val_acc\": [],\n        \"round_val_avg_f1\": []\n    }\n\n    for it in range(iters):\n        print(f\"\\n[AL Round {it+1}/{iters}] — Labeled samples: {len(labeled_dataset)}\")\n\n        train_loader = DataLoader(labeled_dataset, batch_size=batch_size)\n        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n\n\n        #print class distribution of each batch\n        if False:\n            for i, batch in enumerate(train_loader):\n                y_batch = batch[\"y\"]\n                print_distribution(y_batch.tolist(), name=f\"Batch {i}\")\n\n\n        \n        epoch_stats = []\n\n        epochs = final_epochs\n\n        if variable_epochs:  \n            if it <= 3:\n                epochs = 5\n            elif 4 <= it <= 10:\n                epochs = 10\n            elif 11 <= it:\n                epochs = final_epochs\n            else:\n                epochs = final_epochs\n\n        \n        \n        for ep in tqdm(range(epochs), desc=\"Epoch\", leave=False):\n            tr_loss, tr_acc, tr_f1s, tr_avgf1 = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n            val_loss, val_f1s, val_acc, val_avgf1 = _eval_perf(model, val_loader, device, loss_fn)\n\n            epoch_stats.append({\n                \"train_loss\": tr_loss,\n                \"train_acc\": tr_acc,\n                \"train_avg_f1\": tr_avgf1,\n                \"val_loss\": val_loss,\n                \"val_acc\": val_acc,\n                \"val_avg_f1\": val_avgf1\n            })\n\n        history[\"samples\"].append(len(labeled_dataset))\n        history[\"epoch_metrics\"].append(epoch_stats)\n        history[\"round_val_acc\"].append(val_acc)\n        history[\"round_val_avg_f1\"].append(val_avgf1)\n\n        # Query next samples\n        if len(unlabeled_dataset) < query_size:\n            print(\"Unlabeled pool exhausted.\")\n            break\n\n        selected_idxs = query_samples(model, unlabeled_dataset, query_size, strategy, device)\n\n        new_x = [unlabeled_dataset.X[i] for i in selected_idxs]\n        new_y = [unlabeled_dataset.y[i] for i in selected_idxs]\n\n        labeled_dataset.X = torch.cat([labeled_dataset.X, torch.stack(new_x)], dim=0)\n        labeled_dataset.y = torch.cat([labeled_dataset.y, torch.tensor(new_y)], dim=0)\n\n        keep_idxs = list(set(range(len(unlabeled_dataset))) - set(selected_idxs))\n        unlabeled_dataset.X = torch.stack([unlabeled_dataset.X[i] for i in keep_idxs])\n        unlabeled_dataset.y = torch.tensor([unlabeled_dataset.y[i] for i in keep_idxs])\n\n        print(f\"\\nEpoch {epochs}/{epochs}\")\n        print(f\"Train — Loss: {tr_loss:.4f} | Acc: {tr_acc:.4f} | Avg F1: {tr_avgf1:.4f}\")\n        print(f\"Val   — Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | Avg F1: {val_avgf1:.4f}\")\n\n        \n        plot_round_metrics(history)\n\n    plot_final_performance(history)\n    return history\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:49:18.639359Z","iopub.execute_input":"2025-07-31T09:49:18.639696Z","iopub.status.idle":"2025-07-31T09:49:18.663401Z","shell.execute_reply.started":"2025-07-31T09:49:18.639667Z","shell.execute_reply":"2025-07-31T09:49:18.662277Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"all_histories = {}\n\nfor initial_labeled, iters,query_size in data:\n    initial_labeled= 1-initial_labeled/len(X_pool)\n    X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(X_pool, y_pool, test_size=initial_labeled, stratify=y_pool, random_state=42)\n    print(f\"X_labeled shape: {X_labeled.shape}\")\n    print(f\"y_labeled shape: {y_labeled.shape}\")\n    print_distribution(y_labeled, name=\"X_labeled\")\n    print(f\"X_unlabeled shape: {X_unlabeled.shape}\")\n    print(f\"y_unlabeled shape: {y_unlabeled.shape}\")\n    print_distribution(y_unlabeled, name=\"X_unlabeled\")\n\n    \n    \n    labeled_dataset = Dataset(X_labeled, y_labeled)\n    unlabeled_dataset = Dataset(X_unlabeled, y_unlabeled)\n    val_dataset = Dataset(X_val, y_val)\n\n    \n    \n    for strat in strategies:\n        print(f\"\\n=== Running strategy: {strat.upper()} ===\")\n        \n        # Reset datasets to initial versions (deepcopy to avoid mutations)\n        labeled = copy.deepcopy(labeled_dataset)\n        unlabeled = copy.deepcopy(unlabeled_dataset)\n    \n        model.load_state_dict(copy.deepcopy(initial_state_dict))\n        \n        hist = active_learning_loop(\n            model,\n            labeled_dataset=labeled,\n            unlabeled_dataset=unlabeled,\n            val_dataset=val_dataset,\n            strategy=strat,\n            device=device,\n            iters=iters,\n            query_size=query_size,\n            final_epochs=epochs,\n            loss_mode=loss_mode,\n            batch_size=batch_size\n        )\n        \n        all_histories[(strat, initial_labeled, iters, query_size)] = hist\n\n\nwith open(\"/kaggle/working/history_entropy.pkl\", \"wb\") as f:\n    pickle.dump(all_histories, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:49:18.664487Z","iopub.execute_input":"2025-07-31T09:49:18.664783Z","execution_failed":"2025-07-31T09:49:46.891Z"},"_kg_hide-output":true},"outputs":[{"name":"stdout","text":"X_labeled shape: (100, 6, 28)\ny_labeled shape: (100,)\nDistribution in X_labeled:\n  Class 0: 45 (45.0%)\n  Class 1: 13 (13.0%)\n  Class 2: 42 (42.0%)\nX_unlabeled shape: (15900, 6, 28)\ny_unlabeled shape: (15900,)\nDistribution in X_unlabeled:\n  Class 0: 7220 (45.4%)\n  Class 1: 2069 (13.0%)\n  Class 2: 6611 (41.6%)\n\n=== Running strategy: MARGIN ===\n\n[AL Round 1/3] — Labeled samples: 100\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  40%|████      | 2/5 [00:19<00:29,  9.84s/it]","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# Plotting final result","metadata":{}},{"cell_type":"code","source":"#figuring out different data sizes\n\ndef eff_total_labeled_samples(init, iterations, query):\n    return round(iterations * init + query * (iterations * (iterations - 1)) // 2)\n\ndef total_labeled_samples(init, iterations, query):\n    return init+query*iterations\n\ndef best_cumsum(available):\n    best = (0, 0, 0, 0)  # (cumsum, init, step, n)\n    for init in range(1, available + 1):\n        for step in range(1, available + 1):\n            # max possible n for this init and step\n            max_n = (available - init) // step\n            for n in range(1, max_n + 1):\n                total = init + n * step\n                if total <= available:\n                    cumsum = n * init + step * n * (n - 1) // 2\n                    if cumsum > best[0]:\n                        best = (cumsum, init, step, n)\n    return best\n\navailable = 100\ncumsum, init, step, n = best_cumsum(available)\nprint(f\"Max cumsum = {cumsum} with init={init}, step={step}, n={n}\")\n\n\nexample = [ (30,20,1), (60,40,1),(120,40,2),(120,80,1),(180,40,3),(300,40,5) ]\n\nfor init,iterations,query in example:\n    print(f'Init: {init}, Iters: {iterations}, Query: {query}, Total: {total_labeled_samples(init, iterations, query)}, Effective: {eff_total_labeled_samples(init, iterations, query)}')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-31T09:49:46.891Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def eff_total_labeled_samples(init, iterations, query):\n    return round(iterations * init + query * (iterations * (iterations - 1)) // 2)\n\ndef total_labeled_samples(init, iterations, query):\n    return init+query*iterations\n\nunique_configs = sorted(set((init_size, iters, query) for (_, init_size, iters, query) in all_histories.keys()))\n\nfor init_size, iters, query in unique_configs:\n    plt.figure(figsize=(12, 5))\n    plt.suptitle(f\"Init: {round(len(X_pool)*(1-init_size))}, Iters: {iters}, Query: {query}, Samples Used: {total_labeled_samples(round(len(X_pool)*(1-init_size)), iters, query)}, Eff Samples: {eff_total_labeled_samples(round(len(X_pool)*(1-init_size)), iters, query)}\", fontsize=14)\n    # Accuracy\n    plt.subplot(1, 2, 1)\n    for (strat, size, iters_, query_), hist in all_histories.items():\n        if (size, iters_, query_) == (init_size, iters, query):\n            plt.plot(hist[\"samples\"], hist[\"round_val_acc\"], label=strat, marker='o')\n            # Show final accuracy value\n            x_final = hist[\"samples\"][-1]\n            y_final = hist[\"round_val_acc\"][-1]\n            plt.text(x_final, y_final, f\"{y_final:.3f}\", fontsize=8, ha='right', va='bottom')\n    plt.title(\"Validation Accuracy\")\n    plt.xlabel(\"Labeled Samples\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n\n    # F1 Score\n    plt.subplot(1, 2, 2)\n    for (strat, size, iters_, query_), hist in all_histories.items():\n        if (size, iters_, query_) == (init_size, iters, query):\n            plt.plot(hist[\"samples\"], hist[\"round_val_avg_f1\"], label=strat, marker='o')\n            # Show final F1 value\n            x_final = hist[\"samples\"][-1]\n            y_final = hist[\"round_val_avg_f1\"][-1]\n            plt.text(x_final, y_final, f\"{y_final:.3f}\", fontsize=8, ha='right', va='bottom')\n    plt.title(\"Validation Avg F1\")\n    plt.xlabel(\"Labeled Samples\")\n    plt.ylabel(\"Avg F1 Score\")\n    plt.legend()\n\n    plt.tight_layout(rect=[0, 0, 1, 0.95])\n    plt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-31T09:49:46.891Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create export directory\nexport_dir = \"active_learning_results\"\nos.makedirs(export_dir, exist_ok=True)\n\n# Combined CSV file\nall_csv_path = os.path.join(export_dir, \"all_results.csv\")\nwith open(all_csv_path, mode=\"w\", newline='') as all_csv_file:\n    writer_all = csv.writer(all_csv_file)\n    writer_all.writerow([\"strategy\", \"init\", \"iterations\", \"query\", \"sample_size\", \"accuracy\", \"f1_score\"])\n    print(\"strategy,init,iterations,query,sample_size,accuracy,f1_score\")  # Header for print\n\n    for init_size, iters, query in unique_configs:\n        init_abs = round(len(X_pool) * (1 - init_size))\n        filename = f\"results_init{init_abs}_iters{iters}_query{query}.csv\"\n        filepath = os.path.join(export_dir, filename)\n\n        with open(filepath, mode=\"w\", newline='') as f:\n            writer = csv.writer(f)\n            writer.writerow([\"strategy\", \"init\", \"iterations\", \"query\", \"sample_size\", \"accuracy\", \"f1_score\"])\n\n            for (strat, size, iters_, query_), hist in all_histories.items():\n                if (size, iters_, query_) == (init_size, iters, query):\n                    for s, acc, f1 in zip(hist[\"samples\"], hist[\"round_val_acc\"], hist[\"round_val_avg_f1\"]):\n                        row = [strat, init_abs, iters, query, s, round(acc, 6), round(f1, 6)]\n                        print(\",\".join(map(str, row)))   # Print CSV-style row\n                        writer.writerow(row)\n                        writer_all.writerow(row)\n\nprint(f\"\\n✅ All results exported to directory: {export_dir}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-31T09:49:46.891Z"}},"outputs":[],"execution_count":null}]}