{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3549868,"sourceType":"datasetVersion","datasetId":2134482}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rasterio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:19.191074Z","iopub.execute_input":"2025-07-23T08:03:19.191405Z","iopub.status.idle":"2025-07-23T08:03:24.422522Z","shell.execute_reply.started":"2025-07-23T08:03:19.191376Z","shell.execute_reply":"2025-07-23T08:03:24.421800Z"}},"outputs":[{"name":"stdout","text":"Collecting rasterio\n  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\nCollecting affine (from rasterio)\n  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.6.15)\nRequirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.2.1)\nRequirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio) (0.7.2)\nRequirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.26.4)\nRequirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.1.1.2)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.0.9)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24->rasterio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24->rasterio) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24->rasterio) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24->rasterio) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24->rasterio) (2024.2.0)\nDownloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\nInstalling collected packages: affine, rasterio\nSuccessfully installed affine-2.4.0 rasterio-1.4.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import time\nimport torch.utils.data\nimport os\nimport sys\nimport rasterio\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport torch.nn.functional as F\nimport random\nimport re\nimport numpy\nfrom tqdm import tqdm\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom sklearn.metrics import confusion_matrix, f1_score, jaccard_score\nimport seaborn as sns\nimport pandas as pd\n\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport numpy as np\nimport torch\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms.functional as TF\nimport random\nimport numpy as np\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torchvision.transforms import InterpolationMode\nimport random\n\n\nimport torchvision.transforms as T\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import InterpolationMode\nfrom torchvision.transforms.functional import to_tensor\nimport random\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nfrom math import cos,pi\nfrom sklearn.metrics import f1_score, precision_score, recall_score, jaccard_score, accuracy_score, confusion_matrix\nfrom scipy.ndimage import morphology\nfrom scipy.ndimage.filters import maximum_filter1d\nfrom torch.nn import Module, Sequential\nfrom torch.nn import Conv3d, ConvTranspose3d, BatchNorm3d, MaxPool3d, AvgPool1d, Dropout3d\nfrom torch.nn import ReLU, Sigmoid\nfrom torch.utils.data import DataLoader\nfrom torch.autograd import Variable\n\nimport os\nimport rasterio\nfrom glob import glob\nimport matplotlib.pyplot as plt\nfrom rasterio.plot import show\nfrom tqdm import tqdm\nimport numpy as np\nfrom collections import defaultdict\nimport seaborn as sns\nimport pandas as pd\nimport math\n\nimport os\nimport numpy as np\nimport torch\nimport rasterio\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\n\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import random_split\n\nfrom torch.utils.data import ConcatDataset, DataLoader\n\nfrom scipy.stats import mode\n\nimport os\nimport numpy as np\nimport tifffile\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nfrom scipy.stats import skew, kurtosis\nos.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:24.423532Z","iopub.execute_input":"2025-07-23T08:03:24.423827Z","iopub.status.idle":"2025-07-23T08:03:33.357371Z","shell.execute_reply.started":"2025-07-23T08:03:24.423793Z","shell.execute_reply":"2025-07-23T08:03:33.356497Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/2216408665.py:59: DeprecationWarning: Please import `maximum_filter1d` from the `scipy.ndimage` namespace; the `scipy.ndimage.filters` namespace is deprecated and will be removed in SciPy 2.0.0.\n  from scipy.ndimage.filters import maximum_filter1d\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"BASE_PATH = '/kaggle/input/sentinel2-crop-mapping'\nFOLDERS = ['lombardia', 'lombardia2']\nYEARS = ['data2016', 'data2017', 'data2018']\nBANDS = 9\nIMG_SIZE = (48, 48)\nMAX_TILES = 50  # change as needed\n\nlabel_remap = {\n    2: 0, 9: 1, 12: 2, 7: 3,\n    1: 4, 3: 4, 5: 4, 6: 4, 8: 4, 10: 4, 11: 4, 13: 4, 14: 4, 15: 4, 16: 4, 19: 4, 255: 4,\n    4: 5,\n    17: 6, 18: 6, 20: 6, 21: 6\n}\n\ndef remap_labels(mask):\n    return np.vectorize(lambda x: label_remap.get(x, 255))(mask).astype(np.uint8)\n\ndef is_valid_image(file):\n    return file.endswith('.tif') and '_MSAVI' not in file and file != 'y.tif'\n\nall_pixel_metadata = []  # (tile_path, i, j)\nall_band_values = [[] for _ in range(BANDS)]  # for histograms & stats\ntot_pix_count =0 \n\nprint(\"üîç Scanning tiles...\")\nfor region in FOLDERS:\n    for year in YEARS:\n        root = os.path.join(BASE_PATH, region, year)\n        tile_ids = sorted(os.listdir(root))[:MAX_TILES]\n        \n        for tile_id in tqdm(tile_ids, desc=f\"{region}/{year}\"):\n            tile_path = os.path.join(root, tile_id)\n            try:\n                # Load label\n                with rasterio.open(os.path.join(tile_path, 'y.tif')) as src:\n                    y_mask = remap_labels(src.read(1))  # (48,48)\n\n                # Collect valid pixels\n                for i in range(48):\n                    for j in range(48):\n                        if y_mask[i, j] != 255:\n                            all_pixel_metadata.append((tile_path, i, j))\n                            tot_pix_count += 1\n            except:\n                continue\n\nprint(\"Total Pixels: \",tot_pix_count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:06:24.904680Z","iopub.execute_input":"2025-07-23T08:06:24.905323Z","iopub.status.idle":"2025-07-23T08:06:24.934734Z","shell.execute_reply.started":"2025-07-23T08:06:24.905297Z","shell.execute_reply":"2025-07-23T08:06:24.933878Z"}},"outputs":[{"name":"stdout","text":"üîç Scanning tiles...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2310157142.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mYEARS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtile_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mMAX_TILES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtile_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtile_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{region}/{year}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/sentinel2-crop-mapping/lombardia/data2016'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/sentinel2-crop-mapping/lombardia/data2016'","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"label_remap = {\n    2: 0,  # Cereals\n    9: 1,  # Maize\n    12: 2, # Rice\n    7: 3,  # Forage\n    1: 4, 3: 4, 5: 4, 6: 4, 8: 4, 10: 4, 11: 4, 13: 4, 14: 4, 15: 4, 16: 4, 19: 4, 255:4,  # Unknown crop\n    4: 5,  # Woods/tree crops\n    17: 6, 18: 6, 20: 6, 21: 6,  # Non-agricultural\n\n\nde remap_labels(mask, label_remap):\n    return np.vectorize(lambda x: label_remap.get(x, 255))(mask).astype(np.uint8)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.369431Z","iopub.status.idle":"2025-07-23T08:03:33.369657Z","shell.execute_reply.started":"2025-07-23T08:03:33.369551Z","shell.execute_reply":"2025-07-23T08:03:33.369561Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ndef plot_band_histogram(X, band=0, timestep=0, title_prefix=\"\"):\n\n    band_data = X[timestep, band].flatten()\n    \n    plt.figure(figsize=(7, 4))\n    plt.hist(band_data, bins=100, color='blue', alpha=0.7)\n    plt.title(f\"{title_prefix} Band {band} Histogram @ t={timestep}\")\n    plt.xlabel(\"Pixel Value\")\n    plt.ylabel(\"Frequency\")\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.371283Z","iopub.status.idle":"2025-07-23T08:03:33.371608Z","shell.execute_reply.started":"2025-07-23T08:03:33.371452Z","shell.execute_reply":"2025-07-23T08:03:33.371466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nband_sums = np.zeros(BANDS, dtype=np.float64)\nband_sqsums = np.zeros(BANDS, dtype=np.float64)\nband_counts = np.zeros(BANDS, dtype=np.int64)\nall_data = []\n\n\nfor region in FOLDERS:\n    for year in YEARS:\n        tiles_root = os.path.join(BASE_PATH, region, year)\n        tile_ids = sorted(os.listdir(tiles_root))\n        tile_paths = [os.path.join(tiles_root, tile_id) for tile_id in tile_ids[:2500:10]]\n\n        with ThreadPoolExecutor(max_workers=32) as executor:\n            futures = [executor.submit(process_tile, path) for path in tile_paths]\n            for f in tqdm(as_completed(futures), total=len(futures), desc=f\"{region}/{year}\"):\n                result = f.result()\n                if result is not None:\n                    all_data.append(result)\n\n\n# mean and std\nmeans = band_sums / band_counts\nstds = np.sqrt(band_sqsums / band_counts - means ** 2)\nprint(\"\\nüìä Per-band means:\", np.round(means, 2))\nprint(\"üìä Per-band stds: \", np.round(stds, 2))\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.372688Z","iopub.status.idle":"2025-07-23T08:03:33.372921Z","shell.execute_reply.started":"2025-07-23T08:03:33.372821Z","shell.execute_reply":"2025-07-23T08:03:33.372831Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ndef print_band_summary(X, timestep=0, sample_id=0):\n    print(f\"\\nüì¶ Sample {sample_id}, Timestep {timestep}, Shape: {X.shape}\")\n    print(\"Band | Mean     Std     Min     Max     P25     P50     P75     Skew   Kurt\")\n\n    for b in range(X.shape[1]):\n        band_data = X[timestep, b].astype(np.float64).flatten()\n        mean = band_data.mean()\n        std = band_data.std()\n        vmin = band_data.min()\n        vmax = band_data.max()\n        p25 = np.percentile(band_data, 25)\n        p50 = np.percentile(band_data, 50)\n        p75 = np.percentile(band_data, 75)\n        sk = skew(band_data)\n        kurt = kurtosis(band_data)\n        \n        print(f\"{b:>4} | {mean:7.2f} {std:7.2f} {vmin:7.2f} {vmax:7.2f} {p25:7.2f} {p50:7.2f} {p75:7.2f} {sk:7.2f} {kurt:7.2f}\")\n\n# Example usage:\nX, y = all_data[0]\nprint_band_summary(X, timestep=0, sample_id=0)\n\nfor b in range(9):  # for all 9 bands\n    X, _ = all_data[13]\n    plot_band_histogram(X, band=b, timestep=0, title_prefix=\"Before Norm\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.373649Z","iopub.status.idle":"2025-07-23T08:03:33.373896Z","shell.execute_reply.started":"2025-07-23T08:03:33.373793Z","shell.execute_reply":"2025-07-23T08:03:33.373804Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Z-score normalisaiton\nfor i in range(len(all_data)):\n    X, y = all_data[i]\n    X = X.astype(np.float32)  \n    for b in range(BANDS):\n        X[:, b] = (X[:, b] - means[b]) / stds[b]\n    all_data[i] = (X, y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.375097Z","iopub.status.idle":"2025-07-23T08:03:33.375406Z","shell.execute_reply.started":"2025-07-23T08:03:33.375283Z","shell.execute_reply":"2025-07-23T08:03:33.375298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef print_band_summary(X, timestep=0, sample_id=0):\n    print(f\"\\nüì¶ Sample {sample_id}, Timestep {timestep}, Shape: {X.shape}\")\n    print(\"Band | Mean     Std     Min     Max     P25     P50     P75     Skew   Kurt\")\n\n    for b in range(X.shape[1]):\n        band_data = X[timestep, b].astype(np.float64).flatten()\n        mean = band_data.mean()\n        std = band_data.std()\n        vmin = band_data.min()\n        vmax = band_data.max()\n        p25 = np.percentile(band_data, 25)\n        p50 = np.percentile(band_data, 50)\n        p75 = np.percentile(band_data, 75)\n        sk = skew(band_data)\n        kurt = kurtosis(band_data)\n        \n        print(f\"{b:>4} | {mean:7.2f} {std:7.2f} {vmin:7.2f} {vmax:7.2f} {p25:7.2f} {p50:7.2f} {p75:7.2f} {sk:7.2f} {kurt:7.2f}\")\n\n# Example usage:\nX, y = all_data[0]\nprint_band_summary(X, timestep=0, sample_id=0)\n\nfor b in range(9):  # for all 9 bands\n    X, _ = all_data[13]\n    plot_band_histogram(X, band=b, timestep=0, title_prefix=\"After Norm\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.376467Z","iopub.status.idle":"2025-07-23T08:03:33.376733Z","shell.execute_reply.started":"2025-07-23T08:03:33.376618Z","shell.execute_reply":"2025-07-23T08:03:33.376631Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_counter = Counter()\n\nfor _, y in all_data:\n    flat_labels = y.flatten()\n    label_counter.update(flat_labels.tolist())\n\n# Sort the label counts\nlabel_counts = dict(sorted(label_counter.items()))\n\n# ‚úÖ Total number of unique labels\nnum_labels = len(label_counts)\n\n# ‚úÖ Total number of labeled pixels\ntotal_pixels = sum(label_counts.values())\n\n\n\n# üîç Print everything\nprint(f\"üî¢ Total unique labels: {num_labels}\")\nprint(f\"üßÆ Total labeled pixels: {total_pixels}\")\nprint(\"üìä Label Frequencies:\")\nfor label, count in label_counts.items():\n    print(f\"  Label {label}: {count} pixels\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.378009Z","iopub.status.idle":"2025-07-23T08:03:33.378275Z","shell.execute_reply.started":"2025-07-23T08:03:33.378130Z","shell.execute_reply":"2025-07-23T08:03:33.378162Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nlabel_counter = Counter()\n\nfor _, mask in all_data:\n    unique, counts = np.unique(mask, return_counts=True)\n    label_counter.update(dict(zip(unique, counts)))\n\nprint(\"Class pixel counts:\", dict(label_counter))\n\nnum_classes = 7\ntotal_pixels = sum(label_counter.values())\n\nweights = []\nfor cls in range(num_classes):\n    cls_count = label_counter.get(cls, 0)\n    if cls_count == 0:\n        weights.append(0.0)  # Unused class\n    else:\n        freq = cls_count / total_pixels\n        weights.append(1.0 / freq)\n\n# Step 5: Convert to torch.Tensor\nclass_weights = torch.tensor(weights, dtype=torch.float32).to(device)\n\nprint(\"Class weights:\", class_weights)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.378783Z","iopub.status.idle":"2025-07-23T08:03:33.379056Z","shell.execute_reply.started":"2025-07-23T08:03:33.378942Z","shell.execute_reply":"2025-07-23T08:03:33.378954Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#fixed seed\nnp.random.seed(13)\n\n#80/20 split\ntotal_len = len(all_data)\ntrain_len = int(0.8 * total_len)\nval_len = total_len - train_len\ntrain_raw, val_raw = random_split(all_data, [train_len, val_len])\n\nprint(f\"Total samples: {len(all_data)}\")\nprint(f\"Train samples: {len(train_raw)}\")\nprint(f\"Test samples:  {len(val_raw)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.380013Z","iopub.status.idle":"2025-07-23T08:03:33.380260Z","shell.execute_reply.started":"2025-07-23T08:03:33.380119Z","shell.execute_reply":"2025-07-23T08:03:33.380128Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef analyze_timesteps(data):\n    timestep_counts = defaultdict(int)\n\n    for X, _ in data:\n        T = X.shape[0]\n        timestep_counts[T] += 1\n\n    # Print detailed info\n    print(\"üìä Unique Time Step Counts:\")\n    for T in sorted(timestep_counts):\n        print(f\"  T = {T}: {timestep_counts[T]} tiles\")\n\n    print(f\"\\nüßÆ Total Unique T values: {len(timestep_counts)}\")\n    return timestep_counts\n\n# Example usage\nanalyze_timesteps(train_raw)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.381817Z","iopub.status.idle":"2025-07-23T08:03:33.382131Z","shell.execute_reply.started":"2025-07-23T08:03:33.381966Z","shell.execute_reply":"2025-07-23T08:03:33.381988Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_sample(X, y, timestep=0, band=3):\n    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\n    img = X[timestep, band]\n    \n    # Normalize visualization range to make contrast visible\n    vmin = np.percentile(img, 2)\n    vmax = np.percentile(img, 98)\n\n    axs[0].imshow(img, cmap='gray', vmin=vmin, vmax=vmax)\n    axs[0].set_title(f'Band {band} @ t={timestep}')\n\n    axs[1].imshow(y, cmap='tab20')\n    axs[1].set_title('Ground Truth')\n\n    plt.tight_layout()\n    plt.show()\n\n\n# Plot a sample\nsample_X, sample_y = all_data[20]\nprint(f\"Image sequence shape: {sample_X.shape}\")  # (T, 9, 48, 48)\nprint(f\"Ground truth shape: {sample_y.shape}\")    # (48, 48)\nplot_sample(sample_X, sample_y, timestep=0, band=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.382729Z","iopub.status.idle":"2025-07-23T08:03:33.383037Z","shell.execute_reply.started":"2025-07-23T08:03:33.382871Z","shell.execute_reply":"2025-07-23T08:03:33.382884Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, in_channels=32*9, num_classes=7, dropout=0.3):\n        super().__init__()\n\n        def res_block(in_ch, out_ch, dilation):\n            skip = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n            return nn.Sequential(\n                nn.Conv2d(in_ch, out_ch, 3, padding=dilation, dilation=dilation),\n                nn.BatchNorm2d(out_ch),\n                nn.ReLU(),\n                nn.Dropout2d(dropout),\n                \n                nn.Conv2d(out_ch, out_ch, 3, padding=dilation, dilation=dilation),\n                nn.BatchNorm2d(out_ch),\n                nn.Dropout2d(dropout),\n                nn.ReLU(),\n                \n                nn.Sequential(skip)  # identity if same shape, otherwise 1x1 conv\n            )\n\n        self.encoder1 = res_block(in_channels, 256, dilation=1)\n        self.encoder2 = res_block(256, 256, dilation=2)\n        self.encoder3 = res_block(256, 256, dilation=4)\n        self.encoder4 = res_block(256, 512, dilation=2)\n        self.encoder5 = res_block(512, 512, dilation=1)\n        self.final_conv = nn.Conv2d(512, num_classes, kernel_size=1)\n\n    def forward(self, x):\n        # Manual forward pass for residual + skip connections\n        def forward_res_block(x, block):\n            skip = block[-1][0](x)\n            out = block[0](x)\n            out = block[1](out)\n            out = block[2](out)\n            out = block[3](out)\n            out = block[4](out)\n            out = block[5](out)\n            out = block[6](out)\n            return F.relu(out + skip)\n\n        x = forward_res_block(x, self.encoder1)\n        x = forward_res_block(x, self.encoder2)\n        x = forward_res_block(x, self.encoder3)\n        x = forward_res_block(x, self.encoder4)\n        x = forward_res_block(x, self.encoder5)\n        return self.final_conv(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.384054Z","iopub.status.idle":"2025-07-23T08:03:33.384459Z","shell.execute_reply.started":"2025-07-23T08:03:33.384310Z","shell.execute_reply":"2025-07-23T08:03:33.384328Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nclass CustomDataset(Dataset):\n    def __init__(self, tiles, label_smoothing=0.1, num_classes=7, augment=False, noise_std=0.01):\n        self.tiles = tiles\n        self.augment = augment\n        self.label_smoothing = label_smoothing\n        self.num_classes = num_classes\n        self.noise_std = noise_std\n\n        self.aug = T.Compose([\n            T.RandomHorizontalFlip(),\n            T.RandomVerticalFlip(),\n            T.RandomRotation(15, interpolation=InterpolationMode.BILINEAR),\n        ])\n\n    def __len__(self):\n        return len(self.tiles)\n\n    def __getitem__(self, idx):\n        X, y = self.tiles[idx]  # X: (32, 9, 48, 48), y: (48, 48)\n        X = torch.from_numpy(X.reshape(-1, 48, 48)).clone()  # shape: (T*9, 48, 48)\n        y = torch.from_numpy(y).long().clone()    # (32*9, 48, 48)\n\n        if self.augment:\n            seed = random.randint(0, 99999)\n            torch.manual_seed(seed)\n            X = self.aug(X)\n            torch.manual_seed(seed)\n            y = self.aug(y.unsqueeze(0)).squeeze(0).long()\n\n        #gaussian noise\n        X = X + torch.randn_like(X) * self.noise_std\n\n        return X.float(), y.long()  \n\ndef get_dataloaders(train_tiles, val_tiles, batch_size=16, timesteps=32):\n    train_tiles = [(X[:timesteps], y) for X, y in train_tiles]\n    val_tiles = [(X[:timesteps], y) for X, y in val_tiles]\n\n    train_ds = CustomDataset(train_tiles, augment=True)\n    val_ds = CustomDataset(val_tiles, augment=False)\n\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n    return train_loader, val_loader\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.385722Z","iopub.status.idle":"2025-07-23T08:03:33.385999Z","shell.execute_reply.started":"2025-07-23T08:03:33.385850Z","shell.execute_reply":"2025-07-23T08:03:33.385865Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"t=32\nnum_epochs = 30\nlr = 1e-3\nweight_decay = 1e-4\nlabel_smoothing = 0.1\n\ntrain_loader, val_loader = get_dataloaders(train_raw, val_raw, batch_size=16, timesteps=t)\n\nmodel = CNN(in_channels=t*9, num_classes=7).to(device) \noptimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\ncriterion = nn.CrossEntropyLoss(weight = class_weights,label_smoothing=label_smoothing)\n\ntrain_losses, val_losses = [], []\ntrain_accs, val_accs = [], []\n\n# --- Training Loop ---\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss, correct, total = 0.0, 0, 0\n\n    for X, y in tqdm(train_loader, desc=f\"[Train] Epoch {epoch+1}/{num_epochs}\"):\n        X, y = X.to(device), y.to(device)\n        optimizer.zero_grad()\n        logits = model(X)\n        loss = criterion(logits, y)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        pred = logits.argmax(1)\n        correct += (pred == y).sum().item()\n        total += y.numel()\n\n    train_losses.append(total_loss / len(train_loader))\n    train_accs.append(100 * correct / total)\n\n    model.eval()\n    val_loss, val_correct, val_total = 0.0, 0, 0\n    with torch.no_grad():\n        for X, y in tqdm(val_loader, desc=f\"[Val] Epoch {epoch+1}/{num_epochs}\", leave=False):\n            X, y = X.to(device), y.to(device)\n            logits = model(X)\n            loss = criterion(logits, y)\n            val_loss += loss.item()\n            pred = logits.argmax(1)\n            val_correct += (pred == y).sum().item()\n            val_total += y.numel()\n\n    val_losses.append(val_loss / len(val_loader))\n    val_accs.append(100 * val_correct / val_total)\n    scheduler.step()\n\n    print(f\"Epoch {epoch+1:02d} | Train Loss: {train_losses[-1]:.4f} | Val Loss: {val_losses[-1]:.4f} | \"\n          f\"Train Acc: {train_accs[-1]:.2f}% | Val Acc: {val_accs[-1]:.2f}%\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.386903Z","iopub.status.idle":"2025-07-23T08:03:33.387188Z","shell.execute_reply.started":"2025-07-23T08:03:33.387025Z","shell.execute_reply":"2025-07-23T08:03:33.387040Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Plotting ---\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label=\"Train Loss\")\nplt.plot(val_losses, label=\"Val Loss\")\nplt.title(\"Loss\")\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(train_accs, label=\"Train Acc\")\nplt.plot(val_accs, label=\"Val Acc\")\nplt.title(\"Accuracy\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.388077Z","iopub.status.idle":"2025-07-23T08:03:33.388367Z","shell.execute_reply.started":"2025-07-23T08:03:33.388226Z","shell.execute_reply":"2025-07-23T08:03:33.388238Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evalutaion","metadata":{}},{"cell_type":"code","source":"def visualize(model, dataset, idx=0, num_classes=7, label_names=None, rgb_bands=(2, 1, 0), timestep=16):\n    model.eval()\n\n    # === Load data ===\n    X, y = dataset[idx]           # X: (C*T, H, W), y: (H, W)\n    X_input = X.unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        pred = model(X_input).argmax(1).squeeze().cpu().numpy()\n\n    y = y.numpy()\n\n    # === Reshape for RGB ===\n    C = 9\n    T = X.shape[0] // C\n    H, W = X.shape[1], X.shape[2]\n\n    X_vis = X.view(T, C, H, W)  # (T, C, H, W)\n    rgb = X_vis[timestep][list(rgb_bands)].numpy()\n    rgb = np.transpose(rgb, (1, 2, 0))\n    rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min() + 1e-6)  # normalize\n\n    # === Color Map and Legend ===\n    cmap = plt.cm.get_cmap('tab10', num_classes)\n    pred_classes = np.unique(pred)\n    gt_classes = np.unique(y)\n\n    pred_legend = [mpatches.Patch(color=cmap(cls), label=label_names[cls]) for cls in pred_classes] if label_names else []\n    gt_legend = [mpatches.Patch(color=cmap(cls), label=label_names[cls]) for cls in gt_classes] if label_names else []\n\n    # === Plotting ===\n    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n\n    # Top row: Pred and GT\n    axs[0, 0].imshow(pred, cmap=cmap, vmin=0, vmax=num_classes-1)\n    axs[0, 0].set_title(\"Predicted\")\n    axs[0, 0].axis(\"off\")\n    if pred_legend:\n        axs[0, 0].legend(handles=pred_legend, bbox_to_anchor=(1.05, 1), loc='upper left')\n\n    axs[0, 1].imshow(y, cmap=cmap, vmin=0, vmax=num_classes-1)\n    axs[0, 1].set_title(\"Ground Truth\")\n    axs[0, 1].axis(\"off\")\n    if gt_legend:\n        axs[0, 1].legend(handles=gt_legend, bbox_to_anchor=(1.05, 1), loc='upper left')\n\n    # Bottom left: Satellite RGB\n    axs[1, 0].imshow(rgb)\n    axs[1, 0].set_title(f\"Satellite RGB @ timestep {timestep}\")\n    axs[1, 0].axis(\"off\")\n\n    # Bottom right: hide unused\n    axs[1, 1].axis(\"off\")\n\n    plt.tight_layout()\n    plt.show()\n\nlabel_names = {\n    0: \"Cereals\",\n    1: \"Maize\",\n    2: \"Rice\",\n    3: \"Forage\",\n    4: \"Unknown crop\",\n    5: \"Woods/tree crops\",\n    6: \"Non-agricultural\"\n}\n\nval_tile = [(X[:32], y) for X, y in val_raw]\nval_ds = CustomDataset(val_tile, augment=False)\nvisualize(model, val_ds, idx=15, num_classes=7, label_names=label_names,timestep = 16)\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.388934Z","iopub.status.idle":"2025-07-23T08:03:33.389320Z","shell.execute_reply.started":"2025-07-23T08:03:33.389161Z","shell.execute_reply":"2025-07-23T08:03:33.389178Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_combined(model, loader, label_names, num_classes=7):\n    model.eval()\n    pred_counts = np.zeros(num_classes, dtype=int)\n    gt_counts = np.zeros(num_classes, dtype=int)\n    correct = 0\n    total = 0\n\n    all_preds = []\n    all_gts = []\n\n    with torch.no_grad():\n        for X, y in loader:\n            X, y = X.to(device), y.to(device)\n            preds = model(X).argmax(1)\n\n            preds_np = preds.cpu().numpy().flatten()\n            y_np = y.cpu().numpy().flatten()\n\n            for cls in range(num_classes):\n                pred_counts[cls] += np.sum(preds_np == cls)\n                gt_counts[cls] += np.sum(y_np == cls)\n\n            correct += np.sum(preds_np == y_np)\n            total += y_np.size\n\n            all_preds.extend(preds_np)\n            all_gts.extend(y_np)\n\n    all_preds = np.array(all_preds)\n    all_gts = np.array(all_gts)\n\n    acc = correct / total\n\n    cm = confusion_matrix(all_gts, all_preds, labels=list(range(num_classes)))\n    intersection = np.diag(cm)\n    union = np.sum(cm, axis=0) + np.sum(cm, axis=1) - intersection\n    iou = np.round(intersection / (union + 1e-10),4)\n    class_acc = np.round(intersection / (np.sum(cm, axis=1) + 1e-10),4)\n\n    df = pd.DataFrame({\n        'Class': [label_names[c] for c in range(num_classes)],\n        'Total Pixels': gt_counts,\n        'Pred Pixels': pred_counts,\n        'Accuracy': class_acc,\n        'IoU': iou\n    })\n\n    print(df.to_string(index=False))\n    print(f\"\\nTotal Accuracy: {acc:.4f}\")\n    print(f\"Mean IoU: {np.mean(iou):.4f}\")\n    print(f\"F1 Score (macro): {f1_score(all_gts, all_preds, average='macro'):.4f}\")\n\n    plt.figure(figsize=(10, 5))\n    bar_width = 0.35\n    x = np.arange(num_classes)\n    plt.bar(x - bar_width/2, gt_counts, bar_width, label='Ground Truth', color='skyblue')\n    plt.bar(x + bar_width/2, pred_counts, bar_width, label='Predicted', color='salmon')\n    plt.xlabel(\"Classes\")\n    plt.ylabel(\"Pixel Count\")\n    plt.title(\"Pixel Distribution per Class\")\n    plt.xticks(x, [label_names[cls] for cls in range(num_classes)], rotation=45, ha='right')\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', xticklabels=[label_names[i] for i in range(num_classes)],\n                yticklabels=[label_names[i] for i in range(num_classes)], cmap='Blues')\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.tight_layout()\n    plt.show()\n\n\nevaluate_combined(model, val_loader, label_names, num_classes=7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.390351Z","iopub.status.idle":"2025-07-23T08:03:33.390651Z","shell.execute_reply.started":"2025-07-23T08:03:33.390498Z","shell.execute_reply":"2025-07-23T08:03:33.390511Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading Model","metadata":{}},{"cell_type":"code","source":"epoch = 10\nmodel.load_state_dict(torch.load(f\"model_epoch_{epoch}.pth\"))\nmodel.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:03:33.391612Z","iopub.status.idle":"2025-07-23T08:03:33.391836Z","shell.execute_reply.started":"2025-07-23T08:03:33.391714Z","shell.execute_reply":"2025-07-23T08:03:33.391723Z"}},"outputs":[],"execution_count":null}]}